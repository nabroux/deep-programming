{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【名畫變變變 風格遷移】\n",
    "\n",
    "#### 【組員名單】\n",
    "* 資管四 105306076 許雲輔\n",
    "* 資管四 105306067 林承叡\n",
    "* 資管四 105306005 孫和湉\n",
    "* 廣告四 105405132 宋靜\n",
    "\n",
    "#### 【問題與動機】\n",
    "很多App裡都有把照片轉換成世界級名畫的酷功能。這是怎麼做到的呢？我們該怎麼實作出屬於自己的風格遷移應用？\n",
    "\n",
    "#### 【主題】\n",
    "簡單來說，我們要做的事情就是「將某一張圖片 (風格圖) 的風格，套進另一張圖片 (原圖) 中」。\n",
    "\n",
    "我們將利用著名神經網路「VGG19」的威力，將一張影像的「風格」和「內容」分離開來，進而將風格套到我們的目標圖像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part I - Model \n",
    "我們閱讀了VGG19 及Keras Application的相關文檔，藉此了解神經網路VGG19的架構。\n",
    "\n",
    "接著利用老師上課介紹到的CNN建構方式將其架構出來，最後再載入官方的weight數據。(沒有夠力的硬體設備自己訓練)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, InputLayer\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def generateVGG19(input_tensor):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(InputLayer(input_tensor = input_tensor))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))\n",
    "    \n",
    "    weights_path = 'vgg19_weights_notop.h5'\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II - Functions\n",
    "\n",
    "在進行風格遷移時，我們不只需要一個強大的神經網路來提取圖像的特徵，還需要能夠將風格套進目標圖像的函式。\n",
    "我們希望成品在內容上盡量和「原圖」相近、在風格上則盡量與「風格圖」相近，所以大概會需要以下幾種函式：\n",
    "\n",
    "* 損失函數一 “內容損失”（content loss），代表合成的圖像的特徵與基準圖像的特徵之間的L2距離，確保生成的圖像內容和基準圖像保持一致。\n",
    "* 損失函數二 “風格損失”（style loss），代表合成圖像的特徵與風格圖像的特徵之間的Gram矩陣之間的差異，確保生成圖像的風格和風格圖像保持一致。\n",
    "* 損失函數三 “差異損失”（variation loss），代表合成的圖像局部特徵之間的差異，確保生成的圖像局部特徵的一致性，整體看上去自然不突兀。\n",
    "\n",
    "#### 【套件說明】\n",
    "\n",
    "* **vgg19**：這裡import vgg19 套件是為了直接使用其中的 preprocess_input 函式。\n",
    "* **fmin_l_bfgs_b**：這是一個 scipy 提供的 L-BFGS優化器。\n",
    "* **imsave**：scipy.misc 中的 imsave 可以把數組的型式的資料 (如numpy array) 快速存成圖片。\n",
    "* **PIL**: Python Image Library 裡面有一些好用的影像處理函式，如 ImageEnhance (影像強化)。\n",
    "* **time**：為了計算風格遷移每次迭代所耗費的時間。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications import vgg19\n",
    "from keras import backend as K\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "from scipy.misc import imsave\n",
    "from PIL import Image, ImageEnhance\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# 圖片路徑設置、圖片大小、總迭代次數 等等...\n",
    "base_image_path = 'targets/rooftop.jpg'\n",
    "style_reference_image_path = 'styles/starry night.jpg'\n",
    "results_path = 'results/'\n",
    "iterations = 50\n",
    "pictrue_size = 744\n",
    "\n",
    "source_image = Image.open(base_image_path)\n",
    "source_image= source_image.resize((pictrue_size, pictrue_size))\n",
    "width, height = pictrue_size, pictrue_size\n",
    "\n",
    "def save_img(fname, image, image_enhance=True):  # 圖像增強\n",
    "    image = Image.fromarray(image)\n",
    "    if image_enhance:\n",
    "        # 亮度增強\n",
    "        enh_bri = ImageEnhance.Brightness(image)\n",
    "        brightness = 1.2\n",
    "        image = enh_bri.enhance(brightness)\n",
    "        # 彩度增強\n",
    "        enh_col = ImageEnhance.Color(image)\n",
    "        color = 1.2\n",
    "        image = enh_col.enhance(color)\n",
    "        # 銳度增強\n",
    "        enh_sha = ImageEnhance.Sharpness(image)\n",
    "        sharpness = 1.2\n",
    "        image = enh_sha.enhance(sharpness)\n",
    "    imsave(fname, image)\n",
    "    return\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    預處理圖片，包括變形到(1，width, height)形狀，數據壓到0-1之間\n",
    "    \"\"\"\n",
    "    image = image.resize((width, height))\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)\n",
    "    image = vgg19.preprocess_input(image)\n",
    "    return image\n",
    "\n",
    "def deprocess_image(x):\n",
    "    \"\"\"\n",
    "    將0-1之間的數值變回圖片的形式\n",
    "    \"\"\"\n",
    "    x = x.reshape((width, height, 3))\n",
    "    # 將 preprocess_input 的處理調整回來\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')  # 防止超出255範圍\n",
    "    return x\n",
    "\n",
    "# Gram 矩陣\n",
    "def gram_matrix(x):\n",
    "    assert K.ndim(x) == 3\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        features = K.batch_flatten(x)\n",
    "    else:\n",
    "        features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram\n",
    "\n",
    "# 風格損失\n",
    "def style_loss(style, combination):\n",
    "    assert K.ndim(style) == 3\n",
    "    assert K.ndim(combination) == 3\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    S_C = S-C\n",
    "    channels = 3\n",
    "    size = height * width\n",
    "    return K.sum(K.square(S_C)) / (4. * (channels ** 2) * (size ** 2))\n",
    "\n",
    "# 輸入x，輸出對應於 x 的梯度和 loss\n",
    "def eval_loss_and_grads(x):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((1, 3, height, width))\n",
    "    else:\n",
    "        x = x.reshape((1, height, width, 3))\n",
    "    outs = f_outputs([x])  # 輸入x，得到輸出\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "# 內容損失\n",
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination - base))\n",
    "\n",
    "# 差異損失\n",
    "def total_variation_loss(x,img_nrows=width, img_ncols=height):\n",
    "    assert K.ndim(x) == 4\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        a = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, 1:, :img_ncols - 1])\n",
    "        b = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, :img_nrows - 1, 1:])\n",
    "    else:\n",
    "        a = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
    "        b = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))\n",
    "\n",
    "\n",
    "# 打包成 Evaluator 方便運行及計算\n",
    "class Evaluator(object):\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把原圖，風格圖片，結果圖片處理成一個 (3, width, height, 3)的矩陣\n",
    "base_image = K.variable(preprocess_image(source_image))\n",
    "style_reference_image = K.variable(preprocess_image(load_img(style_reference_image_path)))\n",
    "combination_image = K.placeholder((1, width, height, 3))\n",
    "# 組合以上3張圖片，當成一個 keras輸入向量\n",
    "input_tensor = K.concatenate([base_image, style_reference_image, combination_image], axis=0)\n",
    "\n",
    "model = generateVGG19(input_tensor=input_tensor)\n",
    "print(\"Model loaded.\")\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "\n",
    "loss = K.variable(0.)\n",
    "layer_features = outputs_dict['block5_conv2']\n",
    "base_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "content_weight = 0.08\n",
    "loss += content_weight * content_loss(base_image_features,\n",
    "                                      combination_features)\n",
    "feature_layers = ['block1_conv1','block2_conv1','block3_conv1','block4_conv1','block5_conv1']\n",
    "feature_layers_w = [0.1,0.1,0.4,0.3,0.1]\n",
    "\n",
    "for i in range(len(feature_layers)):\n",
    "    # 每一層的權重以及數據\n",
    "    layer_name, w = feature_layers[i], feature_layers_w[i]\n",
    "    layer_features = outputs_dict[layer_name]  # 該層的特徵\n",
    "\n",
    "    style_reference_features = layer_features[1, :, :, :]  # 參考圖像在VGG網絡中第i層的特徵\n",
    "    combination_features = layer_features[2, :, :, :]     # 結果圖像在VGG網絡中第i層的特徵\n",
    "\n",
    "    loss += w * style_loss(style_reference_features, combination_features)  # 目標風格圖像的特徵和結果圖像特徵之間的差異作爲loss\n",
    "\n",
    "loss += total_variation_loss(combination_image)\n",
    "\n",
    "\n",
    "# 求得梯度，輸入combination_image，對loss求梯度, 每輪迭代中combination_image會根據梯度方向做調整\n",
    "grads = K.gradients(loss, combination_image)\n",
    "\n",
    "outputs = [loss]\n",
    "if isinstance(grads, (list, tuple)):\n",
    "    outputs += grads\n",
    "else:\n",
    "    outputs.append(grads)\n",
    "\n",
    "f_outputs = K.function([combination_image], outputs)\n",
    "\n",
    "evaluator = Evaluator()\n",
    "x = preprocess_image(source_image)\n",
    "img = deprocess_image(x.copy())\n",
    "fname = results_path + '原始圖片.png'\n",
    "save_img(fname, img)\n",
    "\n",
    "# 開始迭代\n",
    "for i in range(iterations):\n",
    "    start_time = time.time()\n",
    "    print('iteration', i,end=\"   \")\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), fprime=evaluator.grads, maxfun=20, epsilon=1e-7)\n",
    "    print('目前loss:', min_val,end=\"  \")\n",
    "    img = deprocess_image(x.copy())\n",
    "\n",
    "    fname = 'result_%d.png' % i\n",
    "    end_time = time.time()\n",
    "    print('耗時%.2f s' % (end_time - start_time))\n",
    "\n",
    "    if i%5 == 0 or i == iterations-1:\n",
    "        save_img(results_path + fname, img, image_enhance=True)\n",
    "        print('文件保存爲', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c064a72e75e40dca5b891437c240658",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='n', options=('rooftops',), value='rooftops'), Output()), _dom_clas…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.showTarget(n)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def showTarget(n):\n",
    "    plt.imshow('targets' + n)\n",
    "\n",
    "interact(showTarget, n=['rooftops'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
