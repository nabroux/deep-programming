{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 自建 vgg19 參考 https://gist.github.com/baraldilorenzo/8d096f48a1be4a2d660d\n",
    "* vgg19 的預處理法 caffe https://medium.com/@sci218mike/%E5%9C%96%E7%89%87%E9%A0%90%E8%99%95%E7%90%86%E4%BD%BF%E7%94%A8keras-applications-%E7%9A%84-preprocess-input-6ef0963a483e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Dropout, Input\n",
    "from keras.layers import Conv2D, MaxPooling2D, InputLayer\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def generateVGG19(input_tensor):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(InputLayer(input_tensor = input_tensor))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1'))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool'))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool'))\n",
    "\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3'))\n",
    "    model.add(Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv4'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool'))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv4'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool'))\n",
    "\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3'))\n",
    "    model.add(Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv4'))\n",
    "    model.add(MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool'))\n",
    "    \n",
    "    weights_path = 'vgg19_weights_notop.h5'\n",
    "    model.load_weights(weights_path, by_name=True)\n",
    "\n",
    "    sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy')\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "import numpy as np\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "import time\n",
    "import argparse\n",
    "from scipy.misc import imsave\n",
    "from keras.applications import vgg19\n",
    "from keras import backend as K\n",
    "import os\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageOps, ImageEnhance, ImageFilter\n",
    "\n",
    "base_image_path = 'targets/rooftop.jpg'\n",
    "style_reference_image_path = 'styles/starry night.jpg'\n",
    "results_path = 'results/'\n",
    "iterations = 200\n",
    "pictrue_size = 440\n",
    "\n",
    "source_image = Image.open(base_image_path)\n",
    "source_image= source_image.resize((pictrue_size, pictrue_size))\n",
    "width, height = pictrue_size, pictrue_size\n",
    "\n",
    "def save_img(fname, image, image_enhance=True):  # 圖像增強\n",
    "    image = Image.fromarray(image)\n",
    "    if image_enhance:\n",
    "        # 亮度增強\n",
    "        enh_bri = ImageEnhance.Brightness(image)\n",
    "        brightness = 1.2\n",
    "        image = enh_bri.enhance(brightness)\n",
    "        # 色度增強\n",
    "        enh_col = ImageEnhance.Color(image)\n",
    "        color = 1.2\n",
    "        image = enh_col.enhance(color)\n",
    "        # 銳度增強\n",
    "        enh_sha = ImageEnhance.Sharpness(image)\n",
    "        sharpness = 1.2\n",
    "        image = enh_sha.enhance(sharpness)\n",
    "    imsave(fname, image)\n",
    "    return\n",
    "\n",
    "def preprocess_image(image):\n",
    "    \"\"\"\n",
    "    預處理圖片，包括變形到(1，width, height)形狀，數據歸一到0-1之間\n",
    "    :param image: 輸入一張圖片\n",
    "    :return: 預處理好的圖片\n",
    "    \"\"\"\n",
    "    image = image.resize((width, height))\n",
    "    image = img_to_array(image)\n",
    "    image = np.expand_dims(image, axis=0)  # (width, height)->(1，width, height)\n",
    "    image = vgg19.preprocess_input(image)  # 0-255 -> 0-1.0\n",
    "    return image\n",
    "\n",
    "def deprocess_image(x):\n",
    "    \"\"\"\n",
    "    將0-1之間的數據變成圖片的形式返回\n",
    "    :param x: 數據在0-1之間的矩陣\n",
    "    :return: 圖片，數據都在0-255之間\n",
    "    \"\"\"\n",
    "    x = x.reshape((width, height, 3))\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    # 'BGR'->'RGB'\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')  # 以防超出255範圍\n",
    "    return x\n",
    "\n",
    "# Gram矩陣\n",
    "def gram_matrix(x):\n",
    "    assert K.ndim(x) == 3\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        features = K.batch_flatten(x)\n",
    "    else:\n",
    "        features = K.batch_flatten(K.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = K.dot(features, K.transpose(features))\n",
    "    return gram\n",
    "\n",
    "# 風格損失，是風格圖片與結果圖片的 Gram矩陣之差，並對所有元素求和\n",
    "def style_loss(style, combination):\n",
    "    assert K.ndim(style) == 3\n",
    "    assert K.ndim(combination) == 3\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    S_C = S-C\n",
    "    channels = 3\n",
    "    size = height * width\n",
    "    return K.sum(K.square(S_C)) / (4. * (channels ** 2) * (size ** 2))\n",
    "    #return K.sum(K.pow(S_C,4)) / (4. * (channels ** 2) * (size ** 2))  # 居然和平方沒有什麼不同\n",
    "    #return K.sum(K.pow(S_C,4)+K.pow(S_C,2)) / (4. * (channels ** 2) * (size ** 2))  # 也能用，花後面出現了葉子\n",
    "\n",
    "# 輸入x，輸出對應於 x的梯度和loss\n",
    "def eval_loss_and_grads(x):\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        x = x.reshape((1, 3, height, width))\n",
    "    else:\n",
    "        x = x.reshape((1, height, width, 3))\n",
    "    outs = f_outputs([x])  # 輸入x，得到輸出\n",
    "    loss_value = outs[0]\n",
    "    if len(outs[1:]) == 1:\n",
    "        grad_values = outs[1].flatten().astype('float64')\n",
    "    else:\n",
    "        grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "    return loss_value, grad_values\n",
    "\n",
    "# an auxiliary loss function\n",
    "# designed to maintain the \"content\" of the\n",
    "# base image in the generated image\n",
    "def content_loss(base, combination):\n",
    "    return K.sum(K.square(combination - base))\n",
    "\n",
    "# the 3rd loss function, total variation loss,\n",
    "# designed to keep the generated image locally coherent\n",
    "def total_variation_loss(x,img_nrows=width, img_ncols=height):\n",
    "    assert K.ndim(x) == 4\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        a = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, 1:, :img_ncols - 1])\n",
    "        b = K.square(x[:, :, :img_nrows - 1, :img_ncols - 1] - x[:, :, :img_nrows - 1, 1:])\n",
    "    else:\n",
    "        a = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, 1:, :img_ncols - 1, :])\n",
    "        b = K.square(x[:, :img_nrows - 1, :img_ncols - 1, :] - x[:, :img_nrows - 1, 1:, :])\n",
    "    return K.sum(K.pow(a + b, 1.25))\n",
    "\n",
    "\n",
    "# Evaluator可以只需要進行一次計算就能得到所有的梯度和loss\n",
    "class Evaluator(object):\n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "\n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        loss_value, grad_values = eval_loss_and_grads(x)\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "\n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到需要處理的數據，處理爲keras的變量（tensor），處理爲一個(3, width, height, 3)的矩陣\n",
    "# 分別是基準圖片，風格圖片，結果圖片\n",
    "base_image = K.variable(preprocess_image(source_image))   # 基準圖像\n",
    "style_reference_image = K.variable(preprocess_image(load_img(style_reference_image_path)))\n",
    "combination_image = K.placeholder((1, width, height, 3))\n",
    "# 組合以上3張圖片，作爲一個 keras輸入向量\n",
    "input_tensor = K.concatenate([base_image, style_reference_image, combination_image], axis=0)\n",
    "\n",
    "\n",
    "model = generateVGG19(input_tensor=input_tensor)\n",
    "# model = vgg19.VGG19(input_tensor=input_tensor,weights='imagenet',include_top=False)\n",
    "print(\"Model loaded.\")\n",
    "\n",
    "outputs_dict = dict([(layer.name, layer.output) for layer in model.layers])\n",
    "\n",
    "loss = K.variable(0.)\n",
    "\n",
    "layer_features = outputs_dict['block5_conv2']\n",
    "base_image_features = layer_features[0, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "content_weight = 0.08\n",
    "loss += content_weight * content_loss(base_image_features,\n",
    "                                      combination_features)\n",
    "\n",
    "feature_layers = ['block1_conv1','block2_conv1','block3_conv1','block4_conv1','block5_conv1']\n",
    "feature_layers_w = [0.1,0.1,0.4,0.3,0.1]\n",
    "\n",
    "for i in range(len(feature_layers)):\n",
    "    # 每一層的權重以及數據\n",
    "    layer_name, w = feature_layers[i], feature_layers_w[i]\n",
    "    layer_features = outputs_dict[layer_name]  # 該層的特徵\n",
    "\n",
    "    style_reference_features = layer_features[1, :, :, :]  # 參考圖像在VGG網絡中第i層的特徵\n",
    "    combination_features = layer_features[2, :, :, :]     # 結果圖像在VGG網絡中第i層的特徵\n",
    "\n",
    "    loss += w * style_loss(style_reference_features, combination_features)  # 目標風格圖像的特徵和結果圖像特徵之間的差異作爲loss\n",
    "\n",
    "loss += total_variation_loss(combination_image)\n",
    "\n",
    "\n",
    "# 求得梯度，輸入combination_image，對loss求梯度, 每輪迭代中combination_image會根據梯度方向做調整\n",
    "grads = K.gradients(loss, combination_image)\n",
    "\n",
    "outputs = [loss]\n",
    "if isinstance(grads, (list, tuple)):\n",
    "    outputs += grads\n",
    "else:\n",
    "    outputs.append(grads)\n",
    "\n",
    "f_outputs = K.function([combination_image], outputs)\n",
    "\n",
    "evaluator = Evaluator()\n",
    "x = preprocess_image(source_image)\n",
    "img = deprocess_image(x.copy())\n",
    "fname = results_path + '原始圖片.png'\n",
    "save_img(fname, img)\n",
    "\n",
    "# 開始迭代\n",
    "for i in range(iterations):\n",
    "    start_time = time.time()\n",
    "    print('iteration', i,end=\"   \")\n",
    "    x, min_val, info = fmin_l_bfgs_b(evaluator.loss, x.flatten(), fprime=evaluator.grads, maxfun=20, epsilon=1e-7)\n",
    "    # 一個scipy的L-BFGS優化器\n",
    "    print('目前loss:', min_val,end=\"  \")\n",
    "    # 保存生成的圖片\n",
    "    img = deprocess_image(x.copy())\n",
    "\n",
    "    fname = 'result_%d.png' % i\n",
    "    end_time = time.time()\n",
    "    print('耗時%.2f s' % (end_time - start_time))\n",
    "\n",
    "    if i%5 == 0 or i == iterations-1:\n",
    "        save_img(results_path + fname, img, image_enhance=True)\n",
    "        print('文件保存爲', fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
